\documentclass[a4paper, 12 pt, conference]{ieeeconf}  % 
\IEEEoverridecommandlockouts                              % This command is only
% needed if you want to
% use the \thanks command

\overrideIEEEmargins
% See the \addtolength command later in the file to balance the column lengths
% on the last page of the document

% Pacote de acentuação
\usepackage[brazil]{babel}
\usepackage[utf8]{inputenc}

% The following packages can be found on http:\\www.ctan.org
\usepackage{graphics} % for pdf, bitmapped graphics files
\usepackage{epsfig} % for postscript graphics files
%\usepackage{mathptmx} % assumes new font selection scheme installed
%\usepackage{mathptmx} % assumes new font selection scheme installed
\usepackage{amsmath} % assumes amsmath package installed
\usepackage{amssymb}  % assumes amsmath package installed

\usepackage[]{todonotes} % adicionar parâmetro [disable] para ocultar os comentários
\usepackage{xspace} % usado nos comentários
\usepackage[normalem]{ulem}

\newcounter{todocounter}
\setlength{\marginparwidth}{2cm}
\reversemarginpar
\newcommand{\nota}[1]{\xspace\stepcounter{todocounter}\todo[fancyline]{\thetodocounter: #1}}
\newcommand{\notain}[2]{\stepcounter{todocounter}\todo[inline]{\thetodocounter: (#1) #2}}

\title{\LARGE \bf
Relatório das práticas de aprendizado de máquina.
}

\author{Marcus V. S. Maziero$^{1}$, Paulo R. K. Nakaima$^{2}$, Vitor Hugo Borges Basseto$^{3}$% <-this % stops a space
\thanks{$^{1}$Marcus V. S. Maziero, $^{2}$Paulo R. K. Nakaima e $^{3}$Vitor Hugo Borges Basseto estão vinculados à Universidade Tecnológica Federal do Paraná, Av. Alberto Carazzai, 1640, Cornélio Procópio, Brasil. 
        {\tt\small marcus.maziero$@$outlook.com, nakaima$@$alunos.utfpr.edu.br, vitorhugobasseto$@$gmail.com}}%
}


\begin{document}


\maketitle
\thispagestyle{empty}
\pagestyle{empty}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{abstract}
	Este relatório apresenta os resultado encontrados em 5 práticas de aprendizado de máquinas para classificação de imagens, mais especificamente, classificação de emoções com base em expressões faciais. A partir da Seção~\ref{pratica02} no final de cada uma das seções encontram-se os \textit{links} para o código fonte para desenvolvimento e exibição, sendo que o último possibilita ao leitor a execução imediata dos experimentos em qualquer navegador moderno.
\end{abstract}

\begin{keywords}
	Inteligencia Artificial, Emoções, Imagens, Machine Learning.
\end{keywords}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%A Tabela \ref{Tabela_Exemplo} mostra um exemplo para inserir tabelas nesse documento e a Figura \ref{Figura_Exemplo} mostra um exemplo para inserir figuras nesse documento \cite{Buerger1989}.
%
%\begin{table}[!htbp]
%    \caption{Table Type Styles}
%    \begin{center}
%        \begin{tabular}{|c|c|c|c|}
%            \hline
%            \textbf{Table}&\multicolumn{3}{|c|}{\textbf{Table Column Head}} \\
%            \cline{2-4} 
%            \textbf{Head} & \textbf{\textit{Table column subhead}}& \textbf{\textit{Subhead}}& \textbf{\textit{Subhead}} \\
%            \hline
%            copy& More table copy$^{\mathrm{a}}$& &  \\
%            \hline
%        \end{tabular}
%    \label{Tabela_Exemplo}
%    \end{center}
%\end{table}
%
%\begin{figure}[!htbp]
%    \centering
%    \includegraphics[width=0.8\linewidth,clip=true,trim=0cm 0cm 0cm 0cm, keepaspectratio=true]{Figura_Exemplo.png}
%    \caption{Example of a figure caption.}
%    \label{Figura_Exemplo}
%\end{figure}
%
%É importante também adicionar citações ao longo do texto para mostrar fundamentações, afirmações e trabalhos relacionados. Mais infomações sobre a adição de referências podem ser encontradas em \cite{BibTeX2014}.

\section{INTRODUÇÃO}
\section{OBJETIVO}
\section{RESUMO - DEEP LEARNING}
\section{PRÁTICA 01}
\label{pratica01}
Nesta prática busca-se selecionar as bases de imagens, os descritores para extração de características e os classificadores.

\subsection{Base de dados}
Foi selecionada a base de imagens CKPLUS. A qual pode ser encontrada em: https://www.kaggle.com/shawon10/ckplus. Contém 981 imagens de rostos em escalas de cinza com as expressões de raiva, nojo, desprezo, medo, felicidade, tristeza, surpresa. Para este trabalho foram selecionadas apenas as expressões raiva, medo, felicidade, tristeza e surpresa.

A segunda base de imagens selecionada foi a Yale Face Database. A qual pode ser encontrada em: http://vision.ucsd.edu/content/yale-face-database. Contém 165 imagens em tons de cinza de rostos de 15 indivíduos fazendo 6 expressões faciais, normal, tristeza, sonolência, surpresa e piscando.

\subsection{Extração de características}
Para extração de características foi utilizado o Local Binary Patterns (LBP) e o Gabor. Sendo que o primeiro extrai 256 caracterísitcas de textura e o último 60. Os arquivos finais podem ser encontrados em: https://drive.google.com/drive/folders/1ZP-CkuoP2mQggsR2sd9QGcbks1hrt68u?usp=sharing.

\subsection{Seleção dos classificadores}
Os classificadores utilizados nas práticas seguintes foram selecionados com base em \cite{rajan:19}. Os classificadores são Regressão Logística (Logistic Regression - LR), K vizinhos mais próximos (k-nearest neighbors - KNN), Máquina de Vetores Suporte (Support Vectors Machine - SVM), rede perceptron multicamadas (Multi-layer Perceptron - MLP).

\section{PRÁTICA 02}
\label{pratica02}
Nesta prática busca-se comparar a acurácia obtida por diferentes classificadores a partir dos arquivos gerados na Seção~\ref{pratica01}.

\subsection{Descritor LBP}
\subsubsection{Seleção da técnica de normalização}
A partir dos arquivos gerados com os descritores foram alterandas as técnicas de normalizações para verificar qual delas atinge melhor resultado para acurácia. Para a base de dados CKPLUS com o descritor LBP as diferenças são mínimas como podem ser vistas na Figura~\ref{fig:bar_norm_all_lbp}. Os classificadores utilizados foram: LR, KNN, SVM, MLP.

\begin{figure}[!htbp]
	\centering
	\includegraphics[width=1.0\linewidth,clip=true,trim=0cm 0cm 0cm 0cm, keepaspectratio=true]{bar_norm_all_lbp.png}
	\caption{Comparação de técnicas de normalização com descritor LBP.}
	\label{fig:bar_norm_all_lbp}
\end{figure}

O classificador MLP com a normalização Standard foi a que obteve o melhor resultado, 97\% de acurácia. O pior resultado foi obtido pelo classificador KNN com a normalização Max Absolute, 77\%.

\subsection{Descritor Gabor}
Para o descritor Gabor as diferenças entre os resultados obtidos foi alta para o classificador KNN, contudo nenhum dos classificadores obtiveram 50\% de acurácia. A técnica de normalização Min-Max que consiste em transformar cada característica com valor mínimo em 0 e os valores máximos em 1, sendo que o restando é tranformado em um valor decima entre 0 e 1, obteve a melhor acurácia com o classificador KNN, 41\%. O pior desempenho foi obtido pelo classificador KNN com a normalização Standard, 21\%. Os resultados podem ser vistos na Figura~\ref{fig:bar_norm_all_gabor} Foram mantidos os classificadores utilizados no último experimento.

\begin{figure}[!htbp]
	\centering
	\includegraphics[width=1.0\linewidth,clip=true,trim=0cm 0cm 0cm 0cm, keepaspectratio=true]{bar_norm_all_gabor.png}
	\caption{Comparação de técnicas de normalização com descritor Gabor.}
	\label{fig:bar_norm_all_gabor}
\end{figure}

\subsubsection{Desenvolvimento} Prática 02 - ckplus  - LBP - all - norm; Prática 02 - ckplus  - Gabor - all - norm
\subsubsection{Exibição e Execução} ATUALIZAR

\section{PRÁTICA 03}
\label{pratica03}

Neste experimento busca-se utilizar aprendizado não supervisionado com o classificador \textit{k-means} de modo a obter o melhor valor de \textit{k}. Além disto busca-se reduzir a dimensão do conjunto de dados de modo a reter 90\% de variância.

\subsection{Descritor LBP}
\subsubsection{Redução de dimensionalidade}

Buscou-se reduzir a dimensionalidade do conjunto de dados obtidos com o descritor LBP de modo a reter 90\% de variância. Primeiramente os dados foram normalizados com a técnica Standard, ou seja, são calculados a média e o desvio padrão da conjunto de amostras, em seguida é subraída de cada amostra a média, o resultado então é divido pelo desvio padrão. Esta técnica foi selecionada pois obteve resultado levemente superior as outras técnicas na Seção~\ref{pratica02}.

Com a técnica PCA para redução de dimensionalidade foi selecionado o menor número de componentes que retinha 90\% de variância. Ver Figura~\ref{fig:points_pca_lbp}. Foi possível reduzir de 256 para 133 característica.

\begin{figure}[!htbp]
	\centering
	\includegraphics[width=1.0\linewidth,clip=true,trim=0cm 0cm 0cm 0cm, keepaspectratio=true]{points_pca_lbp.png}
	\caption{Selecionar o menor número de componentes retendo 90\% de variância.}
	\label{fig:points_pca_lbp}
\end{figure}

\subsubsection{Agrupamento}
Com a redução de dimensionalidade obtida foi utilizado o classificador k-means agrupando as amostras de 2 a 30 agrupamentos de forma iterativa. Ao fim, foi compilado e plotado a variância para cada quantidade de agrupamentos para aplicar o método elbow com intuito de definir a melhor quantidade de agrupamentos. O ponto mais distante da reta formada pela ligação do ponto inicial ao final foi 9, o melhor número de agrupamentos. Ver Figura~\ref{fig:points_elbow_lbp}. O agrupamento final foi plotado destancando-se os centróides na Figura~\ref{fig:scatter_k9_lbp}.

\begin{figure}[!htbp]
	\centering
	\includegraphics[width=1.0\linewidth,clip=true,trim=0cm 0cm 0cm 0cm, keepaspectratio=true]{points_elbow_lbp.png}
	\caption{Selecionar o melhor número de agrupamentos.}
	\label{fig:points_elbow_lbp}
\end{figure}

\begin{figure}[!htbp]
	\centering
	\includegraphics[width=1.0\linewidth,clip=true,trim=0cm 0cm 0cm 0cm, keepaspectratio=true]{scatter_k9_lbp.png}
	\caption{Conjuto de amostras agrupados em 9.}
	\label{fig:scatter_k9_lbp}
\end{figure}

\subsection{Descritor Gabor}
\subsubsection{Redução de dimensionalidade}
Foi aplicada a técnica PCA para as características extraídas com o descritor Gabor. Primeiramente os dados  foram normalizados com a técnica MinMax, melhor resultado obtido no experimento anterior. Foi possível reduzir as características de 60 para duas retendo 100\% de variância. Ver  Figura~\ref{fig:points_pca_gabor}.

\begin{figure}[!htbp]
	\centering
	\includegraphics[width=1.0\linewidth,clip=true,trim=0cm 0cm 0cm 0cm, keepaspectratio=true]{points_pca_gabor.png}
	\caption{Selecionar o menor número de componentes retendo 100\% de variância.}
	\label{fig:points_pca_gabor}
\end{figure}

\subsubsection{Agrupamento}
Na sequência foi utilizado o classificador k-means agrupando as amostras de 2 a 30 agrupamentos de forma iterativa. Ao fim, foi compilado e plotado a variância para cada quantidade de agrupamentos para aplicar o método elbow com intuito de definir a melhor quantidade de agrupamentos. O ponto mais distante da reta formada pela ligação do ponto inicial ao final foi 8, o melhor número de agrupamentos. Ver Figura~\ref{fig:points_elbow_gabor}. O agrupamento final foi plotado destancando-se os centróides na Figura~\ref{fig:scatter_k8_gabor}.

\begin{figure}[!htbp]
	\centering
	\includegraphics[width=1.0\linewidth,clip=true,trim=0cm 0cm 0cm 0cm, keepaspectratio=true]{points_elbow_gabor.png}
	\caption{Selecionar o melhor número de agrupamentos.}
	\label{fig:points_elbow_gabor}
\end{figure}

\begin{figure}[!htbp]
	\centering
	\includegraphics[width=1.0\linewidth,clip=true,trim=0cm 0cm 0cm 0cm, keepaspectratio=true]{scatter_k8_gabor.png}
	\caption{Conjuto de amostras agrupados em 8.}
	\label{fig:scatter_k8_gabor}
\end{figure}

Nota-se que o agrupamento plotado na Figura~\ref{fig:scatter_k8_gabor} possui fronteiras mais definidas do que na Figura~\ref{fig:scatter_k9_lbp}.

\subsubsection{Desenvolvimento} Prática 03 - ckplus - LBP - pca - kmeans; Prática 03 - ckplus - Gabor - pca - kmeans
\subsubsection{Exibição e Execução} ATUALIZAR

\section{PRÁTICA 04}
\label{pratica04}
Nesta prática busca-se comparar os resultados de aprendizado supervisionado realizado nos experimentos anteriores com o método Label Propagation.

\subsection{Descritor LBP}
\subsubsection{Seleção dos parâmetros para o método Label Propagation}
O método Label Propagation pode ser utilizado com o kernel de k vizinhos mais próximos (K-Nearest Neighbors - KNN) e funçao de base radial (Radial Basis Function - RBF). Para o  primeiro caso deve-se definir o número máximo de iterações o número de vizinhos e outros. Para o RBF deve-se definir o valor $\gamma$ (gama), a quantidade máxima de iterações e outros.

Para este experimento variou-se o kernel entre KNN e RBF, o valor gama em 20, 25, 30, a quantidade máxima de iterações em 300, 500, 1000 e o número de vizinhos em 7, 14, 21 e 28. Para cada combinação foi feita a validação cruzada em 5 partições. O critério para definição dos melhores parâmetros foi a $\mu$ (média) da acurácia. Os melhores parâmetros para o kernel KNN e RBF estão descritos na Tabela~\ref{tab:meida_acuracia_lp_lbp}. Para todos os classificadores o desempenho da acurácia apresentou queda quando comparado as técnincas supervisionadas. Contudo existe a redução de 600 imagens rotuladas para 360. A comparação com os resultados das práticas supervisionadas podem ser vistas na Figura~\ref{fig:super_vs_semi_lbp}.


\begin{table}[!htbp]
    \caption{Média e desvio padrão para acurácia}
    \begin{center}
        \begin{tabular}{lllllll}
        	Kernel & It. Máx. & N. Vizinhos & $\gamma$ & $\mu$ & $\sigma$ & Posição \\
        	\hline
        	KNN    & 300             & 7                  & n/a  & 0.39       & 0.021               & 1       \\
        	\hline
        	RBF    & 300             & n/a                & 20   & 0.10       & 0.003               & 13      \\
        \end{tabular}
    \label{tab:meida_acuracia_lp_lbp}
    \end{center}
\end{table}

\begin{figure}[!htbp]
	\centering
	\includegraphics[width=1.0\linewidth,clip=true,trim=0cm 0cm 0cm 0cm, keepaspectratio=true]{bar_supervisionado_vs_semi_lbp.png}
	\caption{Supervisionado vs Semi-supervisionado.}
	\label{fig:super_vs_semi_lbp}
\end{figure}

\subsubsection{Desenvolvimento} Prática 02 - ckplus  - LBP - standard; Prática 04 - ckpuls - LBP - gridsearch - both; Prática 04 - ckpuls - LBP - supervisionado vs  semi-supervisionado
\subsubsection{Exibição e Execução} ATUALIZAR

\section{PRÁTICA 05}
\label{pratica05}

Nesta prática busca-se
\section{CONCLUSÃO E TRABALHOS FUTUROS}

Neste trabalho foi realizado o reconhecimento de expressões faciais com aprendizado de máquina. Foram comparadas com base na acurácia o melhor desempenho para os descritores LBP e Gabor. O primeiro foi que obteve melhor resultado. Foram comparadas diferentes técnicas de normalização sendo que os testes realizados com o descritor Gabor foi o que apresentou maior sensibilidade para este tipo de alteração. Além disto foi aplicada a técnica de redução de dimensionalidade com o PCA, novamente os resultados baseados no descritor Gabor foi o mais afetado.

\bibliography{referencias}
\bibliographystyle{plain}

\end{document}
